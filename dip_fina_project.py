# -*- coding: utf-8 -*-
"""Dip_Fina_Project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1A82LigdWS7sAntxft6clr86EfxS76AsZ

CELL 1: Setup and Data Download
Installs necessary libraries, downloads the dataset from Kaggle, and arranges the workspace.
"""

# 1. Install Necessary Libraries
# Added 'graphviz' for model architecture plotting
!apt-get install -y graphviz libgraphviz-dev > /dev/null
!pip install -q kagglehub split-folders opencv-python pydot graphviz

import kagglehub
import os
import shutil
import splitfolders
import numpy as np
import tensorflow as tf
import cv2
import random
import gc
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.utils import class_weight
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers, models, optimizers
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.utils import plot_model

# 2. Download Dataset
print("‚¨áÔ∏è The dataset is being downloaded from Kagglehub...")
path = kagglehub.dataset_download("shashwatwork/identification-of-pseudopapilledema")
print("‚úÖ Download Complete:", path)

# 3. Move Data to Workspace
original_dataset_dir = '/content/raw_data'
if os.path.exists(original_dataset_dir):
    shutil.rmtree(original_dataset_dir)
shutil.copytree(path, original_dataset_dir)

print(f"üìÇ Data moved to workspace: {original_dataset_dir}")

"""CELL 2: Data Splitting (Train/Val/Test)
Splits the data into 70% Training, 15% Validation, and 15% Testing sets.
"""

# Output Folder
output_path = '/content/dataset_split'

# Clear if exists
if os.path.exists(output_path):
    shutil.rmtree(output_path)

print("\n‚úÇÔ∏è The dataset is being divided into Train/Val/Test (70% - 15% - 15%)...")

# Seed=1337 (For Reproducibility)
splitfolders.ratio(original_dataset_dir, output=output_path,
                   seed=1337, ratio=(.7, .15, .15), group_prefix=None)

print("‚úÖ Separation complete!")
print(f"üìÇ Location: {output_path}")

# Define Paths
train_dir = os.path.join(output_path, 'train')
val_dir = os.path.join(output_path, 'val')
test_dir = os.path.join(output_path, 'test')

BATCH_SIZE = 32
IMG_SIZE = (224, 224)

"""CELL 3: Engineering-Level Image Processing Pipeline
Here we define CLAHE (Contrast) and Unsharp Masking (Sharpening). This is your custom "Preprocessing Engine".
"""

# ==========================================
# 1. IMAGE PROCESSING FUNCTIONS
# ==========================================

def apply_clahe(img):
    """
    Contrast Limited Adaptive Histogram Equalization.
    Balances uneven illumination in fundus images.
    """
    img = np.array(img, dtype=np.uint8)
    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    cl = clahe.apply(l)
    limg = cv2.merge((cl, a, b))
    return cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)

def apply_unsharp_mask(img):
    """
    Sharpening filter.
    Highlights the edges of the optic disc (Crucial for Papilledema).
    """
    img = np.array(img, dtype=np.uint8)
    gaussian = cv2.GaussianBlur(img, (9, 9), 10.0)
    # Formula: Original + Amount * (Original - Blurred)
    return cv2.addWeighted(img, 1.5, gaussian, -0.5, 0, img)

# ==========================================
# 2. AUGMENTATION PIPELINE
# ==========================================

def engineered_augmentation_pipeline(img):
    """
    Applies deterministic improvements (CLAHE+Sharpen) + random augmentations.
    """
    # 1. Deterministic (Always Apply)
    img = apply_clahe(img)
    img = apply_unsharp_mask(img)

    # 2. Stochastic (Randomly Apply for Training)
    # Gamma Correction (Simulate lighting conditions)
    if random.random() < 0.5:
        gamma = random.uniform(0.8, 1.2)
        invGamma = 1.0 / gamma
        table = np.array([((i / 255.0) ** invGamma) * 255 for i in np.arange(0, 256)]).astype("uint8")
        img = cv2.LUT(img, table)

    # Gaussian Blur (Simulate focus error - Rare)
    if random.random() < 0.1:
        img = cv2.GaussianBlur(img, (3, 3), 0)

    return img.astype(np.float32)

print("‚úÖ Image Processing Engine (CLAHE + Unsharp + Augmentation) Ready.")

"""CELL 4: Calculating Class Weights
Manages class imbalance and assigns clinical priority to the Papilledema class.
"""

# ================================
# CLASS WEIGHT CALCULATION
# ================================
def get_safe_class_weights(train_dir):
    print("‚öñÔ∏è Calculating Class Weights...")
    try:
        # Temporary generator to count classes
        temp_gen = ImageDataGenerator().flow_from_directory(
            train_dir, target_size=(224,224), batch_size=32, shuffle=False
        )
        train_classes = temp_gen.classes

        # Compute balanced weights
        weights = class_weight.compute_class_weight(
            class_weight='balanced', classes=np.unique(train_classes), y=train_classes
        )
        weight_dict = dict(enumerate(weights))

        # üî¥ CLINICAL PRIORITY: Increase weight for Papilledema
        class_indices = temp_gen.class_indices
        if 'Papilledema' in class_indices:
             idx = class_indices['Papilledema']
             weight_dict[idx] *= 1.5
             print(f"‚ö†Ô∏è Clinical Adjustment: Papilledema weight increased (Index {idx}).")

        print(f"‚úÖ Final Weights: {weight_dict}")
        return weight_dict
    except Exception as e:
        print(f"‚ö†Ô∏è Error calculating weights: {e}")
        return None

# Calculate weights once
class_weights_dict = get_safe_class_weights(train_dir)

import cv2
import numpy as np
import matplotlib.pyplot as plt
import os
import random

# ==========================================
# 1. FONKSƒ∞YONLAR (DIP PIPELINE)
# ==========================================

def apply_clahe(img):
    img = np.array(img, dtype=np.uint8)
    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    cl = clahe.apply(l)
    limg = cv2.merge((cl, a, b))
    return cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)

def apply_unsharp_mask(img):
    img = np.array(img, dtype=np.uint8)
    gaussian = cv2.GaussianBlur(img, (9, 9), 10.0)
    # Form√ºl: Original + 1.5 * (Original - Blurred)
    return cv2.addWeighted(img, 1.5, gaussian, -0.5, 0, img)

# ==========================================
# 2. Choose an image and process
# ==========================================
image_dir = '/content/dataset_split/test/Papilledema'

if os.path.exists(image_dir) and len(os.listdir(image_dir)) > 0:
    # Rastgele bir resim se√ß
    rand_img = random.choice(os.listdir(image_dir))
    img_path = os.path.join(image_dir, rand_img)
    print(f"üì∏ Se√ßilen Resim: {rand_img}")

    # A. ORIGINAL IMAGE
    original_bgr = cv2.imread(img_path)
    original_rgb = cv2.cvtColor(original_bgr, cv2.COLOR_BGR2RGB)

    # B. sTEP 1: ONLY CLAHE
    step1_clahe = apply_clahe(original_rgb)

    # C. STEP 2: CLAHE + Unsharp Masking (Final Hali)
    step2_final = apply_unsharp_mask(step1_clahe)


    plt.figure(figsize=(18, 6))

    # 1. Original
    plt.subplot(1, 3, 1)
    plt.imshow(original_rgb)
    plt.title("1. Raw Image (Orijinal)", fontsize=14, fontweight='bold')
    plt.axis('off')

    # 2. AFTER CLAHE
    plt.subplot(1, 3, 2)
    plt.imshow(step1_clahe)
    plt.title("2. After CLAHE\n(Contrast Enhanced)", fontsize=14, fontweight='bold')
    plt.axis('off')

    # 3. CLAHE + Unsharp (Final)
    plt.subplot(1, 3, 3)
    plt.imshow(step2_final)
    plt.title("3. CLAHE + Unsharp Masking\n(Final Input to Model)", fontsize=14, fontweight='bold', color='darkgreen')
    plt.axis('off')

    plt.tight_layout()
    plt.show()

else:
    print("‚ùå Created. The specified folder was not found or is empty. Please check the 'image_dir' path.")

"""CELL 5: Model Architecture Definition
Helper function to build Transfer Learning models.
"""

def create_transfer_model(base_model, num_classes=3, model_name="Model"):
    # 1. Freeze Base Model
    base_model.trainable = False

    # 2. Add Custom Head
    inputs = base_model.input
    x = base_model.output
    x = layers.GlobalAveragePooling2D(name="global_avg_pool")(x)
    x = layers.BatchNormalization(name="batch_norm")(x) # Stabilizes training
    x = layers.Dense(256, activation='relu', name="dense_256")(x)
    x = layers.Dropout(0.5, name="dropout")(x) # Prevents Overfitting
    outputs = layers.Dense(num_classes, activation='softmax', name="predictions")(x)

    model = models.Model(inputs=inputs, outputs=outputs, name=model_name)

    # 3. Compile
    model.compile(optimizer=optimizers.Adam(learning_rate=0.0001),
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])
    return model

print("‚úÖ Model Builder Function Defined.")

"""CELL 6: TRAINING LOOP - The Most Critical Cell
Here, we chain your "Engineered Pipeline" with the model's own "Preprocessing" function to ensure correct data flow.General Evaluation Phase Tests the trained models on the Test Set and plots Confusion Matrices.
"""

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import gc
import os

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import plot_model

# Model Preprocessing Fonksiyonlarƒ±
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobile_prep
from tensorflow.keras.applications.densenet import preprocess_input as dense_prep
from tensorflow.keras.applications.efficientnet import preprocess_input as eff_prep

# =================================================
# 1. AYARLAR & HELPERLAR
# =================================================
BATCH_SIZE = 32
IMG_SIZE = (224, 224)
EPOCHS_PHASE_1 = 20
EPOCHS_PHASE_2 = 15

model_configs = [
    ("MobileNetV2", tf.keras.applications.MobileNetV2, mobile_prep),
    ("DenseNet121", tf.keras.applications.DenseNet121, dense_prep),
    ("EfficientNetB0", tf.keras.applications.EfficientNetB0, eff_prep)
]

def merge_history(h1, h2):
    if h1 is None: return h2
    if h2 is None: return h1

    if not hasattr(h2, 'history'):
        return h1

    combined = {}
    # h1.history i√ßindeki anahtarlarƒ± (loss, accuracy vs.) al
    for k in h1.history.keys():
        if k in h2.history:
            combined[k] = h1.history[k] + h2.history[k]
        else:
            combined[k] = h1.history[k]

    class CombinedHistory:
        def __init__(self, hist_dict):
            self.history = hist_dict

    return CombinedHistory(combined)

def plot_combined_history(history_obj, model_name):
    if not hasattr(history_obj, 'history'):
        print("‚ö†Ô∏è The graph could not be drawn: Invalid history object.")
        return

    hist = history_obj.history
    acc = hist.get('accuracy', [])
    val_acc = hist.get('val_accuracy', [])
    loss = hist.get('loss', [])
    val_loss = hist.get('val_loss', [])

    if len(acc) == 0:
        print("‚ö†Ô∏è The graph data is empty..")
        return

    plt.figure(figsize=(14, 5))

    # Accuracy
    plt.subplot(1, 2, 1)
    plt.plot(acc, label='Training Accuracy')
    plt.plot(val_acc, label='Validation Accuracy')
    if len(acc) > EPOCHS_PHASE_1:
        plt.axvline(x=EPOCHS_PHASE_1-1, color='green', linestyle='--', label='Fine Tuning Start')
    plt.legend(loc='lower right')
    plt.title(f'{model_name} - Accuracy')
    plt.grid(True)

    # Loss
    plt.subplot(1, 2, 2)
    plt.plot(loss, label='Training Loss')
    plt.plot(val_loss, label='Validation Loss')
    if len(loss) > EPOCHS_PHASE_1:
        plt.axvline(x=EPOCHS_PHASE_1-1, color='green', linestyle='--', label='Fine Tuning Start')
    plt.legend(loc='upper right')
    plt.title(f'{model_name} - Loss')
    plt.grid(True)
    plt.show()

# =================================================
# 2. ROBUST TRAINING LOOP (G√úNCELLENMƒ∞≈û AUGMENTATION)
# =================================================
print("\nüöÄ TRAINING PIPELINE (GEOMETRIC + PIXEL AUGMENTATION) STARTED...")

for model_name, app_module, model_prep_func in model_configs:
    print(f"\n" + "="*60)
    print(f"üëâ MODEL: {model_name}")
    print("="*60)

    # --- A. DATA PIPELINES  ---
(CLAHE + Unsharp + Gamma + Blur)
    def train_chain(img):
        img = engineered_augmentation_pipeline(img)
        img = model_prep_func(img)
        return img

    def val_chain(img):
        img = apply_clahe(img)
        img = apply_unsharp_mask(img)
        img = model_prep_func(img)
        return img


    train_gen = ImageDataGenerator(
        preprocessing_function=train_chain,

        # --- LAYERS ---
        rotation_range=20,
        width_shift_range=0.1,
        height_shift_range=0.1,
        zoom_range=0.1,
        horizontal_flip=True,
        vertical_flip=True,
        fill_mode='nearest'

    ).flow_from_directory(
        train_dir,
        target_size=IMG_SIZE,
        batch_size=BATCH_SIZE,
        class_mode='categorical'
    )

    val_gen = ImageDataGenerator(
        preprocessing_function=val_chain
    ).flow_from_directory(
        val_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical'
    )

    # --- B. PHASE 1 ---
    base_model = app_module(weights="imagenet", include_top=False, input_shape=(224, 224, 3))
    base_model.trainable = False
    model = create_transfer_model(base_model, num_classes=3, model_name=model_name)

    callbacks_ph1 = [
        EarlyStopping(monitor="val_loss", patience=4, restore_best_weights=True, verbose=1),
        ModelCheckpoint(f"{model_name}_phase1.keras", monitor='val_accuracy', save_best_only=True, verbose=0)
    ]

    history1 = model.fit(train_gen, epochs=EPOCHS_PHASE_1, validation_data=val_gen, class_weight=class_weights_dict, callbacks=callbacks_ph1)

    # --- C. PHASE 2 ---
    base_model.trainable = True
    fine_tune_at = int(len(base_model.layers) * 0.8)
    for layer in base_model.layers[:fine_tune_at]: layer.trainable = False
    for layer in model.layers:
        if isinstance(layer, tf.keras.layers.BatchNormalization): layer.trainable = False

    model.compile(optimizer=Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])

    callbacks_ph2 = [
        EarlyStopping(monitor="val_loss", patience=5, restore_best_weights=True, verbose=1),
        ReduceLROnPlateau(monitor="val_loss", factor=0.2, patience=2, verbose=1),
        ModelCheckpoint(f"{model_name}_best.keras", monitor='val_accuracy', save_best_only=True, verbose=1)
    ]

    try:
        history2 = model.fit(train_gen, epochs=EPOCHS_PHASE_2, initial_epoch=len(history1.history['loss']),
                             validation_data=val_gen, class_weight=class_weights_dict, callbacks=callbacks_ph2)
        final_history = merge_history(history1, history2)
    except:
        final_history = history1

    plot_combined_history(final_history, model_name)

    # CLEAR MEMORY
    del model, base_model, history1, train_gen, val_gen
    if 'history2' in locals(): del history2
    tf.keras.backend.clear_session()
    gc.collect()

"""CELL 8: Detailed Class-Based Statistics
Shows breakdown of success rate and confidence levels per class.
"""

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
import tensorflow as tf
import cv2
import os
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# PREPROCESS FUNC
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobile_prep
from tensorflow.keras.applications.densenet import preprocess_input as dense_prep
from tensorflow.keras.applications.efficientnet import preprocess_input as eff_prep



TEST_DIR = '/content/dataset_split/test'
IMG_SIZE = (224, 224)
BATCH_SIZE = 32

#MODELS TO ANALYZE
models_config = [
    ("MobileNetV2", "MobileNetV2_best.keras", mobile_prep),
    ("DenseNet121", "DenseNet121_best.keras", dense_prep),
    ("EfficientNetB0", "EfficientNetB0_best.keras", eff_prep)
]

# DIP Pipeline (CLAHE + Unsharp)
def base_image_processing(img):
    img = np.array(img, dtype=np.uint8)
    # CLAHE
    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    cl = clahe.apply(l)
    limg = cv2.merge((cl, a, b))
    final_img = cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)
    # Unsharp
    gaussian = cv2.GaussianBlur(final_img, (9, 9), 10.0)
    final_img = cv2.addWeighted(final_img, 1.5, gaussian, -0.5, 0, final_img)
    return final_img

# ==========================================
# 2. CATA COLLECTION LOOP
# ==========================================
all_stats = []
class_labels = []

print("üöÄ MODELLER LOADING AND ANALYZING...\n")

for model_name, model_path, prep_func in models_config:

    if not os.path.exists(model_path):

        backup = f"{model_name}_phase1.keras"
        if os.path.exists(backup):
            print(f"‚ö†Ô∏è {model_name}: ''best' was not found, 'phase1' is in use.")
            model_path = backup
        else:
            print(f"‚ùå {model_name}: Model file not found! Skipping.")
            continue

    print(f"‚è≥ {model_name} analyzing...", end=" ")

    # Pipeline Olu≈ütur
    def custom_wrapper(img):
        img = base_image_processing(img)
        return prep_func(img.astype(np.float32))

    try:
        test_gen = ImageDataGenerator(preprocessing_function=custom_wrapper).flow_from_directory(
            TEST_DIR, target_size=IMG_SIZE, batch_size=BATCH_SIZE,
            class_mode='categorical', shuffle=False
        )
        class_labels = list(test_gen.class_indices.keys())
    except:
        print("Test data error.")
        continue

    # Guess
    model = tf.keras.models.load_model(model_path)
    preds = model.predict(test_gen, verbose=0)
    y_pred = np.argmax(preds, axis=1)
    y_true = test_gen.classes

    # --- statƒ±stƒ±cs ---
    # 1. general accuracy
    acc = accuracy_score(y_true, y_pred) * 100

    # 2. Class base accuracy & confidance
    df = pd.DataFrame({'true': y_true, 'pred': y_pred, 'conf': np.max(preds, axis=1)})

    class_metrics = []
    for idx, label in enumerate(class_labels):
        sub = df[df['true'] == idx]
        if len(sub) > 0:

            cls_acc = np.mean(sub['pred'] == idx) * 100

            corrects = sub[sub['pred'] == idx]
            cls_conf = corrects['conf'].mean() * 100 if len(corrects) > 0 else 0
        else:
            cls_acc, cls_conf = 0, 0

        class_metrics.append({
            'Model': model_name,
            'Class': label,
            'Accuracy': cls_acc,
            'Confidence': cls_conf
        })

    all_stats.append({
        'model': model_name,
        'acc': acc,
        'class_data': class_metrics
    })

    print(f"‚úÖ Completed (Acc: {acc:.2f}%)")
    del model
    tf.keras.backend.clear_session()

# ==========================================
# 3. GRAPHIC DRAWING
# ==========================================
if not all_stats:
    print("‚ùå models couldn't analyzed.")
else:
    # Convert data to Pandas DataFrame (for Seaborn)
    # Class-based data
    flat_data = [item for sublist in [m['class_data'] for m in all_stats] for item in sublist]
    df_class = pd.DataFrame(flat_data)

    # General accuracy data
    df_overall = pd.DataFrame([{'Model': m['model'], 'Accuracy': m['acc']} for m in all_stats])

    # --- GRAFIC 1: GENERAL ACCURACY COMPARISION---
    plt.figure(figsize=(10, 6))
    ax1 = sns.barplot(data=df_overall, x='Model', y='Accuracy', palette='deep')
    plt.title('Overall Model Accuracy Comparison', fontsize=16)
    plt.ylim(0, 110)
    plt.ylabel('Accuracy (%)')
    for container in ax1.containers:
        ax1.bar_label(container, fmt='%.2f%%', padding=3, fontweight='bold')
    plt.show()

    # --- GRAFIC 2: CLASS BASED ANALYZE (PAPILLEDEMA VS OTHERS) ---
    plt.figure(figsize=(14, 7))
    ax2 = sns.barplot(data=df_class, x='Class', y='Accuracy', hue='Model', palette='viridis')
    plt.title('Class-Wise Accuracy Comparison', fontsize=16)
    plt.ylim(0, 115)
    plt.ylabel('Accuracy (%)')
    plt.legend(loc='lower right')
    for container in ax2.containers:
        ax2.bar_label(container, fmt='%.1f%%', padding=3, fontsize=9, fontweight='bold')
    plt.show()

    # --- GRAFIC 3:(CONFIDENCE) ---
    plt.figure(figsize=(14, 7))
    ax3 = sns.barplot(data=df_class, x='Class', y='Confidence', hue='Model', palette='magma')
    plt.title('Average Model Confidence (Certainty) by Class', fontsize=16)
    plt.ylim(0, 115)
    plt.ylabel('Confidence Score (%)')
    plt.legend(loc='lower right')
    for container in ax3.containers:
        ax3.bar_label(container, fmt='%.1f%%', padding=3, fontsize=9)
    plt.show()

    print("\n‚úÖ Graphics created!")

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import tensorflow as tf
import cv2
import os
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobile_prep
from tensorflow.keras.applications.densenet import preprocess_input as dense_prep
from tensorflow.keras.applications.efficientnet import preprocess_input as eff_prep

# ==========================================
# 1. settƒ±ngs
# ==========================================
TEST_DIR = '/content/dataset_split/test'
IMG_SIZE = (224, 224)
BATCH_SIZE = 32


models_config = [
    ("MobileNetV2", "MobileNetV2_best.keras", mobile_prep),
    ("DenseNet121", "DenseNet121_best.keras", dense_prep),
    ("EfficientNetB0", "EfficientNetB0_best.keras", eff_prep)
]

# DIP (CLAHE + Unsharp)
# pipeline
def base_image_processing(img):
    img = np.array(img, dtype=np.uint8)

    # 1. CLAHE (L-Channel)
    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    cl = clahe.apply(l)
    limg = cv2.merge((cl, a, b))
    final_img = cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)

    # 2. Unsharp Masking
    gaussian = cv2.GaussianBlur(final_img, (9, 9), 10.0)
    final_img = cv2.addWeighted(final_img, 1.5, gaussian, -0.5, 0, final_img)

    return final_img

# ==========================================
# 2. LOOP AND VIZUALIZATION
# ==========================================
plt.figure(figsize=(24, 7))

for i, (model_name, model_path, prep_func) in enumerate(models_config):
    print(f"\nüîÑ ANALƒ∞Z EDƒ∞Lƒ∞YOR: {model_name}...")


    if not os.path.exists(model_path):

        backup_path = f"{model_name}_phase1.keras"
        if os.path.exists(backup_path):
            print(f"‚ö†Ô∏è '{model_path}' not found, '{backup_path}' is in use.")
            model_path = backup_path
        else:
            print(f"‚ùå Model fine not dound: {model_path}. models skipped")
            continue

    # Custom Generator
    def custom_wrapper(img):
        #  pipeline (CLAHE+Unsharp)
        img = base_image_processing(img)
        # Normalization etc.
        return prep_func(img.astype(np.float32))

    try:
        test_gen = ImageDataGenerator(preprocessing_function=custom_wrapper).flow_from_directory(
            TEST_DIR, target_size=IMG_SIZE, batch_size=BATCH_SIZE,
            class_mode='categorical', shuffle=False # Shuffle False √ßok √∂nemli!
        )
    except:
        print("‚ùå Test klas√∂r√º hatasƒ±. Yolu kontrol et.")
        continue

    # Tahmin
    model = tf.keras.models.load_model(model_path)
    preds = model.predict(test_gen, verbose=0)
    y_pred = np.argmax(preds, axis=1)
    y_true = test_gen.classes
    class_names = list(test_gen.class_indices.keys())

    # Metrics
    acc = accuracy_score(y_true, y_pred)
    cm = confusion_matrix(y_true, y_pred)


    plt.subplot(1, 3, i+1)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,
                xticklabels=class_names, yticklabels=class_names, annot_kws={"size": 14})

    plt.title(f"{model_name}\nAccuracy: {acc:.2%}", fontsize=16, fontweight='bold')
    plt.ylabel('True', fontsize=12)
    plt.xlabel('Pred', fontsize=12)


    print(f"üìä {model_name} Classification Report:")
    print(classification_report(y_true, y_pred, target_names=class_names))
    print("-" * 60)

    # Clear Memory
    del model
    tf.keras.backend.clear_session()

plt.tight_layout()
plt.show()
print("\n‚úÖ All models analyzing completed!")

import numpy as np
import tensorflow as tf
import cv2
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from tensorflow.keras.models import load_model
import os
import random

# ==========================================
# 1. CONFIGURATION
# ==========================================
# Target Model (Change this to switch models)
MODEL_NAME = "MobileNetV2"  # Options: "MobileNetV2", "DenseNet121", "EfficientNetB0"
MODEL_PATH = f"{MODEL_NAME}_best.keras"

# The specific class you want to analyze (e.g., Papilledema)
TARGET_CLASS = "Papilledema"
TEST_DIR = '/content/dataset_split/test'

# Last Convolutional Layer Names (Specific to Keras architectures)
LAYER_NAMES = {
    "MobileNetV2": "Conv_1",         # Last features before pooling
    "DenseNet121": "relu",           # Last block output
    "EfficientNetB0": "top_activation" # Top layer features
}

# ==========================================
# 2. IMAGE PROCESSING PIPELINE (Must match training)
# ==========================================
def apply_clahe(img):
    img = np.array(img, dtype=np.uint8)
    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    cl = clahe.apply(l)
    limg = cv2.merge((cl, a, b))
    return cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)

def apply_unsharp_mask(img):
    img = np.array(img, dtype=np.uint8)
    gaussian = cv2.GaussianBlur(img, (9, 9), 10.0)
    return cv2.addWeighted(img, 1.5, gaussian, -0.5, 0, img)

def get_img_array(img_path, size=(224, 224)):
    # Load Image
    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # Apply Your Pipeline
    img = apply_clahe(img)
    img = apply_unsharp_mask(img)

    # Resize and keep original for display
    original_img = cv2.resize(img, size)

    # Prepare batch for model
    array = np.expand_dims(original_img, axis=0)
    return array, original_img

# ==========================================
# 3. GRAD-CAM ALGORITHM
# ==========================================
def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):
    # Create a model that maps the input image to the activations
    # of the last conv layer as well as the output predictions
    try:
        grad_model = tf.keras.models.Model(
            inputs=[model.inputs],
            outputs=[model.get_layer(last_conv_layer_name).output, model.output]
        )
    except ValueError:
        print(f"‚ùå Error: Layer '{last_conv_layer_name}' not found in model.")
        return None

    # Compute the gradient of the top predicted class for our input image
    # with respect to the activations of the last conv layer
    with tf.GradientTape() as tape:
        last_conv_layer_output, preds = grad_model(img_array)
        if pred_index is None:
            pred_index = tf.argmax(preds[0])
        class_channel = preds[:, pred_index]

    # This is the gradient of the output neuron (top predicted or chosen)
    # with regard to the output feature map of the last conv layer
    grads = tape.gradient(class_channel, last_conv_layer_output)

    # Vector of weights: mean intensity of the gradient over a specific feature map channel
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))

    # Multiply each channel in the feature map array by "how important this channel is"
    last_conv_layer_output = last_conv_layer_output[0]
    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
    heatmap = tf.squeeze(heatmap)

    # Normalize the heatmap between 0 and 1
    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
    return heatmap.numpy()

def save_and_display_gradcam(img, heatmap, alpha=0.4):
    # Rescale heatmap to a range 0-255
    heatmap = np.uint8(255 * heatmap)

    # Use jet colormap to colorize heatmap
    jet = cm.get_cmap("jet")

    # Use RGB values of the colormap
    jet_colors = jet(np.arange(256))[:, :3]
    jet_heatmap = jet_colors[heatmap]

    # Resize the heatmap to the original image size
    jet_heatmap = cv2.resize(jet_heatmap, (img.shape[1], img.shape[0]))
    jet_heatmap = np.uint8(255 * jet_heatmap)

    # Superimpose the heatmap on original image
    superimposed_img = jet_heatmap * alpha + img
    superimposed_img = np.array(superimposed_img, dtype=np.uint8)

    return superimposed_img

# ==========================================
# 4. EXECUTION
# ==========================================
print(f"‚è≥ Loading Model: {MODEL_PATH}...")

if os.path.exists(MODEL_PATH):
    model = load_model(MODEL_PATH)

    # Select appropriate preprocessing function for the model
    if "MobileNet" in MODEL_NAME:
        from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
    elif "DenseNet" in MODEL_NAME:
        from tensorflow.keras.applications.densenet import preprocess_input
    elif "EfficientNet" in MODEL_NAME:
        from tensorflow.keras.applications.efficientnet import preprocess_input

    # Pick a random image from the Test Set
    target_dir = os.path.join(TEST_DIR, TARGET_CLASS)
    if os.path.exists(target_dir):
        random_file = random.choice(os.listdir(target_dir))
        file_path = os.path.join(target_dir, random_file)
        print(f"üîç Analyzing File: {random_file}")

        # 1. Process Image
        img_array_raw, original_img = get_img_array(file_path)
        img_array = preprocess_input(img_array_raw.copy()) # Normalization

        # 2. Get Prediction
        preds = model.predict(img_array, verbose=0)
        top_pred_idx = np.argmax(preds[0])
        confidence = np.max(preds)
        print(f"ü§ñ Prediction: Class {top_pred_idx} with {confidence:.2%} confidence")

        # 3. Generate Heatmap
        last_layer_name = LAYER_NAMES[MODEL_NAME]
        heatmap = make_gradcam_heatmap(img_array, model, last_layer_name, top_pred_idx)

        if heatmap is not None:
            # 4. Display
            final_img = save_and_display_gradcam(original_img, heatmap)

            plt.figure(figsize=(15, 6))

            # Subplot 1: Original (Processed)
            plt.subplot(1, 3, 1)
            plt.imshow(original_img)
            plt.title("Processed Input\n(CLAHE + Unsharp)")
            plt.axis('off')

            # Subplot 2: Heatmap
            plt.subplot(1, 3, 2)
            plt.imshow(heatmap, cmap='jet')
            plt.title("Grad-CAM Heatmap\n(Attention Map)")
            plt.axis('off')

            # Subplot 3: Overlay
            plt.subplot(1, 3, 3)
            plt.imshow(final_img)
            plt.title("Overlay\n(Red = High Focus)")
            plt.axis('off')

            plt.tight_layout()
            plt.show()
            print("‚úÖ Visualization Complete. Use this image for your report.")
        else:
            print("‚ùå Could not generate heatmap (Layer issue).")
    else:
        print(f"‚ùå Directory not found: {target_dir}")
else:
    print(f"‚ùå Model file not found: {MODEL_PATH}")

"""CELL 9: Visual Comparison Grid
Visually compares model predictions side-by-side.
"""

def visualize_all_models_predictions(dataset_path, model_list):
    print("\nüëÅÔ∏è G√ñRSELLE≈ûTƒ∞RME BA≈ûLIYOR (T√úM MODELLER)...")

    # --- ADIM 1: MODELLERƒ∞ G√úVENLƒ∞ Y√úKLE ---
    loaded_models = {}
    print("‚è≥ Modeller diskten y√ºkleniyor...")

    for name, _, _ in model_list:
        # √ñnce 'best' dosyasƒ±nƒ± ara
        best_path = f"{name}_best.keras"
        phase1_path = f"{name}_phase1.keras"

        target_path = None
        if os.path.exists(best_path):
            target_path = best_path
            print(f"  ‚úÖ {name}: '_best' dosyasƒ± bulundu.")
        elif os.path.exists(phase1_path):
            target_path = phase1_path
            print(f"  ‚ö†Ô∏è {name}: '_best' yok, '_phase1' yedeƒüi kullanƒ±lƒ±yor.")
        else:
            print(f"  ‚ùå {name}: Hi√ßbir model dosyasƒ± bulunamadƒ±!")
            continue

        try:
            model = tf.keras.models.load_model(target_path)
            loaded_models[name] = model
        except Exception as e:
            print(f"  ‚ùå Y√ºkleme hatasƒ± ({name}): {e}")

    if not loaded_models:
        print("‚õî Hƒ∞√áBƒ∞R MODEL Y√úKLENEMEDƒ∞.")
        return

    # --- ADIM 2: GENERATOR OLU≈ûTUR ---
    def display_prep(img):
        return apply_clahe(img)

    try:
        viz_gen = ImageDataGenerator(preprocessing_function=display_prep).flow_from_directory(
            dataset_path, target_size=IMG_SIZE, batch_size=32, shuffle=True
        )
    except Exception as e:
        print(f"‚õî Veri seti y√ºkleme hatasƒ±: {e}")
        return

    # Bir batch resim al
    x_batch, y_batch = next(iter(viz_gen))
    labels = list(viz_gen.class_indices.keys())

    # --- ADIM 3: √áƒ∞ZDƒ∞R ---
    plt.figure(figsize=(20, 20))

    num_images = min(9, len(x_batch))

    for i in range(num_images):
        img = x_batch[i] # CLAHE uygulanmƒ±≈ü resim

        predictions_text = ""
        true_label_idx = np.argmax(y_batch[i])
        true_label = labels[true_label_idx]

        # Sadece Y√úKLENMƒ∞≈û modeller √ºzerinde d√∂n√ºyoruz
        for name, model in loaded_models.items():
            try:
                # 1. Preprocess fonksiyonunu bul
                prep_func = next(cfg[2] for cfg in model_list if cfg[0] == name)

                # 2. Girdiyi Hazƒ±rla
                img_input = apply_unsharp_mask(img)
                img_input = prep_func(img_input)
                img_input = np.expand_dims(img_input, axis=0)

                # 3. Tahmin Et
                pred_prob = model.predict(img_input, verbose=0)
                pred_idx = np.argmax(pred_prob)
                conf = np.max(pred_prob) * 100
                pred_label = labels[pred_idx]

                # 4. Metni Ekle
                mark = "‚úÖ" if pred_label == true_label else "‚ùå"
                predictions_text += f"{mark} {name}: {pred_label} ({conf:.1f}%)\n"
            except Exception as e:
                predictions_text += f"‚ö†Ô∏è {name} Hatasƒ±\n"

        # Resmi √áiz
        plt.subplot(3, 3, i+1)
        img_show = np.array(img, dtype=np.uint8)
        plt.imshow(img_show)

        # Yazƒ± Kutusu
        plt.title(f"TRUE: {true_label}\n" + "-"*30 + "\n" + predictions_text,
                  loc='left', fontsize=10, fontfamily='monospace',
                  backgroundcolor='#f0f0f0', bbox=dict(facecolor='white', alpha=0.9, edgecolor='gray'))
        plt.axis('off')

    plt.tight_layout()
    plt.show()

    # RAM Temizliƒüi
    for model in loaded_models.values():
        del model
    tf.keras.backend.clear_session()
    gc.collect()

# ==========================================
# 3. √áALI≈ûTIR
# ==========================================
visualize_all_models_predictions(test_dir, model_configs)

pip install PyQt6 tensorflow opencv-python numpy

!pip install gradio

import gradio as gr
import tensorflow as tf
import cv2
import numpy as np
from tensorflow.keras.applications.densenet import preprocess_input as dense_prep

# --- 1. CONFIG ---
MODEL_PATH = 'MobileNetV2_best.keras'
CLASS_NAMES = ['Normal', 'Papilledema', 'Pseudopapilledema']

# --- 2. LOAD MODEL ---
print("Loading model...")
try:
    model = tf.keras.models.load_model(MODEL_PATH)
    print("‚úÖ Model loaded successfully!")
except Exception as e:
    print(f"‚ùå ERROR: Model not found at {MODEL_PATH}. Run training first.")
    model = None

# --- 3. PREPROCESSING (Must match Training Logic) ---
def process_image_for_model(img):
    img = np.array(img, dtype=np.uint8)

    # A. Engineering Pipeline (CLAHE + Unsharp)
    # 1. CLAHE
    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    cl = clahe.apply(l)
    limg = cv2.merge((cl, a, b))
    final_img = cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)

    # 2. Unsharp Masking (Sharpening)
    gaussian = cv2.GaussianBlur(final_img, (9, 9), 10.0)
    final_img = cv2.addWeighted(final_img, 1.5, gaussian, -0.5, 0, final_img)

    # B. Resize
    final_img = cv2.resize(final_img, (224, 224))

    # C. Model Specific Preprocessing (DenseNet expects specific scaling)
    # Do NOT use /255.0 manually if using transfer learning functions
    img_input = dense_prep(final_img.astype(np.float32))

    # Add Batch Dimension
    img_input = np.expand_dims(img_input, axis=0)

    return img_input

# --- 4. PREDICTION FUNCTION ---
def predict_eye(image):
    if model is None:
        return None

    # Process
    processed_img = process_image_for_model(image)

    # Predict
    predictions = model.predict(processed_img, verbose=0)[0]

    # Format for Gradio
    return {class_name: float(predictions[i]) for i, class_name in enumerate(CLASS_NAMES)}

# --- 5. UI ---
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown(
        """
        # üëÅÔ∏è AI Papilledema Diagnosis System
        **Model:** MobileNetV2 | **Pipeline:** CLAHE + Unsharp Masking + Transfer Learning
        """
    )

    with gr.Row():
        with gr.Column():
            input_image = gr.Image(label="Upload Fundus Image", type="numpy")
            predict_btn = gr.Button("üîç Analyze", variant="primary")

        with gr.Column():
            output_label = gr.Label(num_top_classes=3, label="Diagnosis Result")

    predict_btn.click(fn=predict_eye, inputs=input_image, outputs=output_label)

print("Starting Gradio...")
demo.launch(debug=True, share=True)